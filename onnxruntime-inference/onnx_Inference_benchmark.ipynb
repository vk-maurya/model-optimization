{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qmPERnxpNPH",
        "outputId": "207b7cd1-c788-4f7a-bfa4-2bed1a461bbe"
      },
      "outputs": [],
      "source": [
        "# %pip install onnxruntime-gpu onnx transformers psutil pandas py-cpuinfo py3nvml coloredlogs wget netron sympy datasets torchmetrics ipython-autotime accelerate protobuf watermark -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EWNcRzupxN1",
        "outputId": "634fe285-7441-4803-bbcd-eae039cbc7a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 101 µs (started: 2024-05-18 17:50:14 +05:30)\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import os.path as op\n",
        "import time\n",
        "\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from watermark import watermark\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "torch.manual_seed(123)\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pKz7kp_qFs9",
        "outputId": "87219311-875f-4258-b37e-201c1b003b4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last updated: 2024-05-18T17:50:18.255726+05:30\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.12.3\n",
            "IPython version      : 8.24.0\n",
            "\n",
            "Compiler    : GCC 11.2.0\n",
            "OS          : Linux\n",
            "Release     : 5.15.146.1-microsoft-standard-WSL2\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 20\n",
            "Architecture: 64bit\n",
            "\n",
            "onnxruntime : 1.17.1\n",
            "onnx        : 1.16.0\n",
            "transformers: 4.41.0\n",
            "accelerate  : 0.30.1\n",
            "datasets    : 2.19.1\n",
            "torchmetrics: 1.4.0.post0\n",
            "pandas      : 2.2.2\n",
            "\n",
            "time: 1.31 s (started: 2024-05-18 17:50:18 +05:30)\n"
          ]
        }
      ],
      "source": [
        "print(watermark())\n",
        "print(watermark(packages=\"onnxruntime,onnx,transformers,accelerate,datasets,torchmetrics,pandas\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwaTVpDdpt5G",
        "outputId": "61a60cf3-986f-4d6f-e574-7225429ca031"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch CUDA available? True\n",
            "time: 30.9 ms (started: 2024-05-18 17:50:22 +05:30)\n"
          ]
        }
      ],
      "source": [
        "print(\"Torch CUDA available?\", torch.cuda.is_available())\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "c74f684c918d49f18e12d876648eeece",
            "481ab94682624ab981a95717c9009f28",
            "4db34daeff2540869846d682a46c0f0a",
            "b257188ca29445b6a9ff90e73378c846",
            "3c6aee6683ad4fc9bf5ae17b23746024",
            "e12f95259ed94fed822db2fb480b7393",
            "250374317d9a4cb08459bc2c92f35f30",
            "803d395d72a84c8985f9c6bc308f71d1",
            "46567763914c4844a5676969b01442e2",
            "8ab7ab272cd3433287d5d1e8a038dfde",
            "c579999eea9d4d4f8b5b5503207fab62",
            "afe8f97f4eb04b6bae90f3f39d82cd8c",
            "7bfef0686b654a7daf322675dfe88954",
            "4fcc587f74ff4171b36f0e809d35cb8c",
            "ca879a396d1a4d5e869783a3b7ba8099",
            "45fb4384dd914cab9ae68a322134ee09",
            "df0b98f6de844596802f7b76d6217fc7",
            "d9adaa1cd37649f5a0faa40112143926",
            "acfb1ea1b0e04cb39d4ba8d5309755b8",
            "aca69b5875e644ae9669ccc2d743a889",
            "2460da69bf824304915dc26ae8e0d8ab",
            "638d726d1cc6439fb80e447a6de683e5"
          ]
        },
        "id": "j9GRvnMjqd2m",
        "outputId": "469721e9-0c32-421d-dc8c-d2e6956e6db1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating CSV from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 34.39ba/s]\n",
            "Creating CSV from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 26.38ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6461083"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 9.77 s (started: 2024-05-18 17:17:52 +05:30)\n"
          ]
        }
      ],
      "source": [
        "data = load_dataset('imdb')\n",
        "data['train'] = data['train'].shuffle(seed=42)\n",
        "data['test'] = data['test'].shuffle(seed=42)\n",
        "\n",
        "# Select only 5000 records from the train and test datasets\n",
        "data['train'] = data['train'].select(range(5000))\n",
        "data['test'] = data['test'].select(range(5000))\n",
        "# saving into csv\n",
        "data['train'].to_csv(\"train.csv\",index=False)\n",
        "data['test'].to_csv(\"validation.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWlyzZvkqnZs",
        "outputId": "aba24a2b-baf5-4349-fd9d-17361be5c367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 143 ms (started: 2024-05-18 17:51:25 +05:30)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import Dataset\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"validation.csv\")\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDrmkQrGq0KU",
        "outputId": "ba78be97-19c1-46d4-b935-400742fe4704"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=2\n",
        ")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3yfkDplrhOT",
        "outputId": "fae00a6c-57dc-4836-941e-51b1b458a653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 262 µs (started: 2024-05-18 17:51:46 +05:30)\n"
          ]
        }
      ],
      "source": [
        "max_len = 512\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loader "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNsrJhIvq_Cl",
        "outputId": "50da97b7-6d77-4b98-adef-917b9630894a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 9.86 s (started: 2024-05-18 17:18:44 +05:30)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define the IMDBDataset class\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len, device):\n",
        "        self.device = device\n",
        "        texts = df.iloc[:, 0].tolist()\n",
        "        labels = df.iloc[:, 1].tolist()\n",
        "\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        for text in texts:\n",
        "            encoding = tokenizer.encode_plus(\n",
        "                text,\n",
        "                add_special_tokens=True,\n",
        "                max_length=max_len,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_attention_mask=True,\n",
        "                return_tensors='pt'  # Get PyTorch tensors\n",
        "            )\n",
        "            input_ids.append(encoding['input_ids'])\n",
        "            attention_masks.append(encoding['attention_mask'])\n",
        "        # Convert the lists into tensors and move them to the device\n",
        "        # so that we don't have to do this on for loop during inference\n",
        "        self.input_ids = torch.cat(input_ids).to(device)\n",
        "        self.attention_masks = torch.cat(attention_masks).to(device)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_masks[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "\n",
        "train= pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"validation.csv\")\n",
        "\n",
        "# Check if CUDA is available and set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Create the dataset and data loader\n",
        "train_dataset = IMDBDataset(train, tokenizer, max_len=max_len, device=device)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Create the dataset and data loader\n",
        "test_dataset = IMDBDataset(test, tokenizer, max_len=max_len, device=device)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kVwuIShrtFs",
        "outputId": "292d40d1-8340-4a0e-e83e-f5adc406ce60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 15.3 ms (started: 2024-05-18 17:19:08 +05:30)\n"
          ]
        }
      ],
      "source": [
        "len(train_dataset[0]['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od7Srmnbq0d8",
        "outputId": "b2d3a865-6d49-4afa-903c-6146ab791bde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [01:38<00:00, 50.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch cuda Inference time = 19.55 ms\n",
            "time: 1min 38s (started: 2024-05-18 17:19:25 +05:30)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "# Measure the latency. It is not accurate using Jupyter Notebook, it is recommended to use standalone python script.\n",
        "latency = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(train_dataset):\n",
        "        # both are already in the device\n",
        "        inputs = {\n",
        "            'input_ids':      batch['input_ids'],\n",
        "            'attention_mask': batch['attention_mask']\n",
        "        }\n",
        "        start = time.time()\n",
        "        outputs = model(**inputs)\n",
        "        latency.append(time.time() - start)\n",
        "print(\"PyTorch {} Inference time = {} ms\".format(device.type, format(sum(latency) * 1000 / len(latency), '.2f')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Onnx Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhp2CEhNs3wg",
        "outputId": "50ee0204-ab11-41cd-9ccd-35295a36d577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 240 µs (started: 2024-05-18 17:53:31 +05:30)\n"
          ]
        }
      ],
      "source": [
        "# !pip install onnxruntime-gpu onnx -q\n",
        "# !pip install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPL5i4-8ttHx",
        "outputId": "4a26252c-8aa1-4922-bc97-6aa6238834a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512])\n",
            "time: 16.1 ms (started: 2024-05-18 17:54:40 +05:30)\n"
          ]
        }
      ],
      "source": [
        "# data type should match to input datatype\n",
        "# input_ids: torch.int64\n",
        "# attention_mask: torch.int64\n",
        "dummy_input = {\n",
        "    'input_ids': torch.randint(0, 1000, (1, max_len)),              \n",
        "    'attention_mask': torch.ones((1, max_len),dtype=torch.int64)    \n",
        "}\n",
        "print(dummy_input['input_ids'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzVdYbQ-ucCG",
        "outputId": "987e693f-be18-4262-d5f2-93b9a0c8b309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.5 ms (started: 2024-05-18 17:56:32 +05:30)\n"
          ]
        }
      ],
      "source": [
        "# putting model and dummy data into same device\n",
        "dummy_input['input_ids'] = dummy_input['input_ids'].to(device)\n",
        "dummy_input['attention_mask'] =  dummy_input['attention_mask'].to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model device: cuda:0\n",
            "Dummy input device: cuda:0\n",
            "time: 660 µs (started: 2024-05-18 17:56:34 +05:30)\n"
          ]
        }
      ],
      "source": [
        "# checking model and dummy data in same device\n",
        "print(f\"Model device: {model.device}\")\n",
        "print(f\"Dummy input device: {dummy_input['input_ids'].device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0KUGAtItZiQ",
        "outputId": "2980a7c8-fafb-491c-cd52-3de237de284e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/miniconda3/envs/hf/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:231: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model has been exported to ONNX format.\n",
            "time: 2.16 s (started: 2024-05-18 16:41:54 +05:30)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import onnx\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(\n",
        "    model,                            # Model being run\n",
        "    (dummy_input['input_ids'], dummy_input['attention_mask']),  # Model input (or a tuple for multiple inputs)\n",
        "    \"model.onnx\",                     # Where to save the model (can be a file or file-like object)\n",
        "    export_params=True,               # Store the trained parameter weights inside the model file\n",
        "    opset_version=11,                 # ONNX version to export the model to\n",
        "    input_names=['input_ids', 'attention_mask'],  # Input names for the model\n",
        "    output_names=['output'],          # Output names for the model\n",
        "    dynamic_axes={\n",
        "        'input_ids': {0: 'batch_size', 1: 'sequence'},\n",
        "        'attention_mask': {0: 'batch_size', 1: 'sequence'}\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Model has been exported to ONNX format.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data loader without putting into Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 3.86 s (started: 2024-05-18 17:25:57 +05:30)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "max_len = 512\n",
        "batch_size = 32\n",
        "\n",
        "# Define the IMDBDataset class\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len, device):\n",
        "        self.device = device\n",
        "        texts = df.iloc[:, 0].tolist()\n",
        "        labels = df.iloc[:, 1].tolist()\n",
        "\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        for text in texts:\n",
        "            encoding = tokenizer.encode_plus(\n",
        "                text,\n",
        "                add_special_tokens=True,\n",
        "                max_length=max_len,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_attention_mask=True,\n",
        "                return_tensors='pt'  # Get PyTorch tensors\n",
        "            )\n",
        "            input_ids.append(encoding['input_ids'])\n",
        "            attention_masks.append(encoding['attention_mask'])\n",
        "\n",
        "        # Convert the lists into tensors \n",
        "        # we are not moving to cuda becuase onnx runtime requires input in cpu\n",
        "        self.input_ids = torch.cat(input_ids)\n",
        "        self.attention_masks = torch.cat(attention_masks)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_masks[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "\n",
        "train= pd.read_csv(\"train.csv\")\n",
        "# test = pd.read_csv(\"validation.csv\")\n",
        "\n",
        "# Check if CUDA is available and set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Create the dataset and data loader\n",
        "train_dataset = IMDBDataset(train, tokenizer, max_len=max_len, device=device)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Create the dataset and data loader\n",
        "# test_dataset = IMDBDataset(test, tokenizer, max_len=max_len, device=device)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "import os\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'GPU'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.26 ms (started: 2024-05-18 18:00:06 +05:30)\n"
          ]
        }
      ],
      "source": [
        "import onnxruntime \n",
        "onnxruntime.get_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running Inference on ONNX runtime with GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6ScQwslCxrfL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[0;93m2024-05-18 17:21:53.745879482 [W:onnxruntime:, inference_session.cc:1914 Initialize] Serializing optimized model with Graph Optimization level greater than ORT_ENABLE_EXTENDED and the NchwcTransformer enabled. The generated model may contain hardware specific optimizations, and should only be used in the same environment the model was optimized in.\u001b[m\n",
            "100%|██████████| 5000/5000 [01:07<00:00, 74.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX Runtime GPU Inference time = 13.16 ms\n",
            "time: 1min 9s (started: 2024-05-18 17:21:51 +05:30)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "import onnxruntime\n",
        "import numpy\n",
        "\n",
        "from tqdm import tqdm\n",
        "assert 'CUDAExecutionProvider' in onnxruntime.get_available_providers()\n",
        "device_name = 'gpu'\n",
        "\n",
        "sess_options = onnxruntime.SessionOptions()\n",
        "output_dir =\"optimized\"\n",
        "# this will create optimized model in output_dir\n",
        "sess_options.optimized_model_filepath = os.path.join(output_dir, \"optimized_model_{}.onnx\".format(device_name))\n",
        "\n",
        "# setting CPU count as intra_op_num_threads\n",
        "sess_options.intra_op_num_threads=psutil.cpu_count(logical=True)\n",
        "# export model path\n",
        "export_model_path  =\"model.onnx\"\n",
        "session = onnxruntime.InferenceSession(export_model_path, sess_options, providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"])\n",
        "\n",
        "latency = []\n",
        "for batch in tqdm(train_dataset):\n",
        "    # Ensure the inputs are 2D (batch_size, sequence_length)\n",
        "    input_ids = batch['input_ids'].reshape(1, max_len).numpy()\n",
        "    attention_mask = batch['attention_mask'].reshape(1, max_len).numpy()\n",
        "\n",
        "    inputs = {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask\n",
        "    }\n",
        "\n",
        "    start = time.time()\n",
        "    outputs = session.run(None, inputs)\n",
        "    latency.append(time.time() - start)\n",
        "\n",
        "print(\"ONNX Runtime GPU Inference time = {} ms\".format(format(sum(latency) * 1000 / len(latency), '.2f')))"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### In above we are creating optimized_model_filepath which we are going to use  without onnxruntime.SessionOptions() option\n",
        "![image.png](attachment:image.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [01:06<00:00, 75.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX Runtime GPU Inference time = 13.09 ms\n",
            "time: 1min 8s (started: 2024-05-18 17:28:39 +05:30)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "import onnxruntime\n",
        "import numpy\n",
        "\n",
        "from tqdm import tqdm\n",
        "assert 'CUDAExecutionProvider' in onnxruntime.get_available_providers()\n",
        "device_name = 'gpu'\n",
        "\n",
        "# sess_options = onnxruntime.SessionOptions()\n",
        "# output_dir =\"optimized\"\n",
        "# sess_options.optimized_model_filepath = os.path.join(output_dir, \"optimized_model_{}.onnx\".format(device_name))\n",
        "\n",
        "# # Please change the value according to best setting in Performance Test Tool result.\n",
        "# sess_options.intra_op_num_threads=psutil.cpu_count(logical=True)\n",
        "# export_model_path  =\"model.onnx\"\n",
        "\n",
        "# using optimized model\n",
        "optimized_model = \"optimized/optimized_model_gpu.onnx\"\n",
        "session = onnxruntime.InferenceSession(optimized_model, providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"])\n",
        "\n",
        "latency = []\n",
        "for batch in tqdm(train_dataset):\n",
        "    # Ensure the inputs are 2D (batch_size, sequence_length)\n",
        "    input_ids = batch['input_ids'].reshape(1, max_len).numpy()\n",
        "    attention_mask = batch['attention_mask'].reshape(1, max_len).numpy()\n",
        "\n",
        "\n",
        "    inputs = {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask\n",
        "    }\n",
        "\n",
        "    start = time.time()\n",
        "    outputs = session.run(None, inputs)\n",
        "    latency.append(time.time() - start)\n",
        "\n",
        "print(\"ONNX Runtime GPU Inference time = {} ms\".format(format(sum(latency) * 1000 / len(latency), '.2f')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX Runtime GPU is 30.61% faster than PyTorch\n",
            "\n",
            "time: 709 µs (started: 2024-05-18 18:09:38 +05:30)\n"
          ]
        }
      ],
      "source": [
        "pytorch_inference_time = 98 #sec           #1 min 38 sec\n",
        "onnx_inference_time = 68 #sec              #1 min 8 sec\n",
        "speed_diff = (pytorch_inference_time - onnx_inference_time) / pytorch_inference_time * 100\n",
        "print(\"ONNX Runtime GPU is {:.2f}% faster than PyTorch\".format(speed_diff))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX Runtime GPU avg Latency is 33.04% faster than PyTorch\n",
            "\n",
            "time: 454 µs (started: 2024-05-18 18:12:11 +05:30)\n"
          ]
        }
      ],
      "source": [
        "# latency analysis\n",
        "pytorch_latency_time = 19.55    # ms \n",
        "onnx_latency_time = 13.09       # ms\n",
        "latency_diff = (pytorch_latency_time - onnx_latency_time) / pytorch_latency_time * 100\n",
        "print(\"ONNX Runtime GPU avg Latency is {:.2f}% faster than PyTorch\".format(latency_diff))\n",
        "print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2460da69bf824304915dc26ae8e0d8ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "250374317d9a4cb08459bc2c92f35f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c6aee6683ad4fc9bf5ae17b23746024": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45fb4384dd914cab9ae68a322134ee09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46567763914c4844a5676969b01442e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "481ab94682624ab981a95717c9009f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e12f95259ed94fed822db2fb480b7393",
            "placeholder": "​",
            "style": "IPY_MODEL_250374317d9a4cb08459bc2c92f35f30",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "4db34daeff2540869846d682a46c0f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803d395d72a84c8985f9c6bc308f71d1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46567763914c4844a5676969b01442e2",
            "value": 1
          }
        },
        "4fcc587f74ff4171b36f0e809d35cb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acfb1ea1b0e04cb39d4ba8d5309755b8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aca69b5875e644ae9669ccc2d743a889",
            "value": 1
          }
        },
        "638d726d1cc6439fb80e447a6de683e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bfef0686b654a7daf322675dfe88954": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df0b98f6de844596802f7b76d6217fc7",
            "placeholder": "​",
            "style": "IPY_MODEL_d9adaa1cd37649f5a0faa40112143926",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "803d395d72a84c8985f9c6bc308f71d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab7ab272cd3433287d5d1e8a038dfde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aca69b5875e644ae9669ccc2d743a889": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acfb1ea1b0e04cb39d4ba8d5309755b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe8f97f4eb04b6bae90f3f39d82cd8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bfef0686b654a7daf322675dfe88954",
              "IPY_MODEL_4fcc587f74ff4171b36f0e809d35cb8c",
              "IPY_MODEL_ca879a396d1a4d5e869783a3b7ba8099"
            ],
            "layout": "IPY_MODEL_45fb4384dd914cab9ae68a322134ee09"
          }
        },
        "b257188ca29445b6a9ff90e73378c846": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ab7ab272cd3433287d5d1e8a038dfde",
            "placeholder": "​",
            "style": "IPY_MODEL_c579999eea9d4d4f8b5b5503207fab62",
            "value": " 1/1 [00:00&lt;00:00, 15.31ba/s]"
          }
        },
        "c579999eea9d4d4f8b5b5503207fab62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c74f684c918d49f18e12d876648eeece": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_481ab94682624ab981a95717c9009f28",
              "IPY_MODEL_4db34daeff2540869846d682a46c0f0a",
              "IPY_MODEL_b257188ca29445b6a9ff90e73378c846"
            ],
            "layout": "IPY_MODEL_3c6aee6683ad4fc9bf5ae17b23746024"
          }
        },
        "ca879a396d1a4d5e869783a3b7ba8099": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2460da69bf824304915dc26ae8e0d8ab",
            "placeholder": "​",
            "style": "IPY_MODEL_638d726d1cc6439fb80e447a6de683e5",
            "value": " 1/1 [00:00&lt;00:00, 14.59ba/s]"
          }
        },
        "d9adaa1cd37649f5a0faa40112143926": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df0b98f6de844596802f7b76d6217fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e12f95259ed94fed822db2fb480b7393": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
